{"meta":{"title":"Discovery Tale","subtitle":"","description":"","author":"Sheldon Lee","url":"https://www.totrav.com","root":"/"},"pages":[{"title":"Xingyu Lei","date":"2023-10-25T00:28:40.272Z","updated":"2023-10-25T00:28:40.272Z","comments":false,"path":"about/index.html","permalink":"https://www.totrav.com/about/index.html","excerpt":"","text":":star: Crazy for Technical Art Self-motivated learner, critical thinker and problem solver Senior Technical Artist :video_game: &emsp; PlayStation, SIE [Apr 2023 - Present] Un-announced Project Design and build a UE5 game cinematics pipeline from scratch Optimize and develop Maya and MotionBuilder Animation tools and workflow Cross-department coordination, code review, new-hire training Technical Artist :video_game: &emsp; PlayStation, SIE [Jan 2021 - Apr 2023] The Last of Us: Part I Engine optimization on framerate and memory Develop and maintain a tool ecosystem that closely supports Naughty Dog across multiple departments: including Character Library, Pose Library, Engine Capture tool and more Virtual face tracking, technical scene prep, rigging QC, PC and PS5 devkit setup Computer Graphics Research Assistant :books: &emsp; Purdue University [Sep 2018 - Dec 2020] Developed a state-machine-based procedural animation system in Unity and integration with a machine-learning-based emotion recognition module Created automation tool for character rigging and mocap retargeting Technical Documentation and Research Paper Drafting CFX TD :art: &emsp; Blur Studio [May - July 2020] [Jun - Aug 2019] CFX pipeline development and optimization Tool development: hair QC, Qualoth IO, version comparer, soft modification, camera toolkit and more Delivered over 70 shots of cloth/hair simulation using Maya and 3dsMax Works The Last of Us: Part I 2022 Love Death & Robots 2020 Call of Duty: Modern Warefare 2019"}],"posts":[{"title":"Hello World","slug":"hello-world","date":"2023-10-24T03:31:53.909Z","updated":"2023-10-24T03:31:53.909Z","comments":true,"path":"post/hello-world/","link":"","permalink":"https://www.totrav.com/post/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"Object-Oriented Design: A Comprehensive Guide to Building Robust and Scalable Software Systems","slug":"general-oo-design","date":"2023-04-02T07:00:00.000Z","updated":"2023-09-02T17:47:49.884Z","comments":true,"path":"post/general-oo-design/","link":"","permalink":"https://www.totrav.com/post/general-oo-design/","excerpt":"","text":"This blog is a second processed product/summary of the tutorial series:Linkedin Learning: Object-Oriented Programming.Bullet points extracted by me and reformatted with help from ChatGPT. Object-oriented design is a fundamental concept in software development thatfocuses on modeling the behavior and characteristics of real-world objects in a program.By understanding the basics of object identity, properties and attributes, behavior, and class, developers can create well-designed, efficient, and maintainable software. IntroductionObject Identity:Objects are unique entities within a program that are separate and distinguishable from one another, even if they belong to the same class or type. Each object has a unique identifier that differentiates it from other objects, and this identity is essential for managing and manipulating objects within a program. Properties and Attributes:Objects have properties or attributes that define their characteristics, such as size, weight, color, and shape. These attributes are essential for representing real-world objects in a program and can be used to distinguish between different objects of the same type. Behavior:Objects have behavior or actions that they can perform, such as filling, swimming, or ringing. Behavior is typically defined as methods or functions that manipulate an object’s attributes or interact with other objects in the program. One of the challenges of object-oriented design is identifying what can be an objectin a program. In general, objects should be represented by nouns and not verbs,and they should have a unique identity, attributes, and behavior. The focus should be on identifying the main objects in the program and their interactions with one another. A class is a template for creating objects in a program. It defines the name, type, attributes, and behavior of objects that belong to that class. A class can be used to create multiple objects of the same type and is an essential component of object-oriented design. Steps for Object-Oriented DesignThe process of object-oriented design involves analyzing and designing the program before writing the code.This includes gathering requirements, describing the application, identifying the main objects, describing the interactions between objects, and creating a class diagram using Unified Modeling Language (UML). Software/System RequirementsIn object-oriented design, understanding the software/system requirements is essential for creating awell-designed, efficient, and maintainable program. Sets of RequirementsSoftware/system requirements can be divided into two sets of questions: what does it need to do? how should it do it? The first set of questions refers to the functionality of the program, while the second set refers to performance, legal, support, and security requirements. Function Requirements:refer to what the system/application must do. These requirements capture the bare necessities of the program and define the core functionality that the program needs to provide. Non-Functional Requirements:define how the system/application should do something. These requirements are concerned with aspects such as usability, reliability, performance, supportability, design, implementation, interface, and physical constraints. FURPS Requirement ModelThe FURPS requirement model is a framework for thinking about software/system requirements.FURPS stands for functionality, usability, reliability, performance, and supportability. Functionalityrefers to the capabilities of the system, while the other four elements are non-functional requirements. Usabilityfocuses on the user and include factors such as human factors UI and documentation.The usability of the program is essential for ensuring that users can efficiently and effectively use the system. Reliabilityis concerned with predictability, availability, and failure rate.These requirements ensure that the program operates consistently and reliably. Performancerelates to speed, efficiency, and limitations. These requirements ensure that the program operates efficiently and effectively, even when processing large amounts of data. Supportabilityis concerned with extensibility, configurability, and testability. These requirements ensure that the program can be maintained and updated over time. Design, Implementation, Interface, and Physical ConstraintsIn addition to the FURPS requirements, other non-functional requirements include design (how the program is built), implementation (the programming language used and standards to follow), interface (the ability of the program to interface with other systems), and physical constraints (the hardware limitations of the system). Use CaseThe use case is a scenario that outlines a particular goal of an actor (user) with the system. It consists of the following elements: 123456[Title] Short and simple goal[Primary Actor] The user who desires to achieve the goal[Success Scenario] Steps or paragraphs describing how to achieve the goal To create a use case,identify the actors who interact with the system and separate them by their roles in the use case, not job titles.Focus on the intent of the goal and not go into too specific steps or too broad a goal.The scenario should be concise and avoid detailed technical implementation or UI elements.Focus on the “sunny-day” scenario and avoid including rarely encountered scenarios.Avoid needless words and keep the scenario short and concise. Conceptual ModelIn object-oriented design, creating a conceptual model is acrucial step in developing a software or system.A conceptual model helps to identify the objects and their relationships that will form the backbone of the software.Here are the steps involved in creating a conceptual model. Identify Objects:The first step is to identify the objects that will be used as class objects in the system.This can be done by looking at the user story or use case and picking out the relevant nouns. For example, in a user story about ordering a meal, the relevant objects might include “customer,” “menu,” and “order.” Identify Class Relationships:Once the objects have been identified, the next step is to connect them with lines to show their relationships.It is important to write down the verbs on each line to avoid using generic words like “use.”Instead, use verbs that describe the relationship between the objects. For example, in the meal ordering system, the “customer” might “place” an “order” from the “menu.” Figure Out Class Responsibilities:The final step is to figure out the responsibilities of each class.This involves identifying the behaviors or actions that each class will perform.This can be done by looking at the user story or use case and picking out the relevant verbs. For example, in the meal ordering system, the “menu” class might have the responsibility of “displaying” the available items while the “order” class might have the responsibility of “calculating” the total cost of the meal. It is important to note that each behavior should belong to the class that is most responsible for it.A behavior usually involves multiple objects, but each object should be responsible for itself.Avoid putting too much responsibility on a single object, which can lead to a “god object” that controls everything in the system. In addition to these steps, another useful tool for creating a conceptual model is CRC (Class Responsibility Collaboration) cards.These cards can be used to organize the classes and their responsibilities, making it easier to visualize the system and identify any potential issues. Class Diagram and Class RelationshipIn object-oriented design, UML class diagrams are used to represent the structure of a system’s classes and the relationships between them.Here are some important considerations when creating UML class diagrams. Each class in a UML class diagram should have a name, attributes, and behaviors.When creating classes, it’s important to focus on the behaviors of the objects,rather than just their attributes. This is because objects are meant to do things,not just hold data.In general, it’s recommended to keep as many class attributes and methods as private as possible,only making them public if we are certain that other objects will need to use them. Constructor: Constructors are considered as behavior and should be treated as such when creating UML class diagrams.In UML, a constructor is represented as a method with the same name as the class. Interface: In UML, abstract classes and interfaces are represented as types.Abstract classes are used to represent a general category of objects,while interfaces are used to represent shared capabilities or behaviors.For example, a draw() interface can be shared between different types of objects that can be drawn on a screen.While objects of different types cannot be categorized under the same abstract class,they can all share the draw() interface to be able to draw on the screen.A system can iterate through all objects and call the draw() interface to update the screen. Principles and PatternsThere are several principles and patterns that can help make our software development more efficient and effective. Single Responsibility Principle: A class should have only one responsibility. Avoid creating god objects that try to do everything. Instead, split responsibilities into multiple classes. Don’t Repeat Yourself (DRY): Avoid duplicating code. Reuse code and extract common functionality into methods or classes. You Ain’t Gonna Need It (YAGNI): Don’t overdo it. Only add features that are necessary and useful. Avoid adding unnecessary complexity. Error Handling and Prompt to Guide Users: Design our software to handle errors gracefully and provide clear prompts to guide users. Good error handling can improve the user experience and prevent bugs. Software Testing: Testing is an important part of software development. Write automated tests to ensure that our code is working as intended and to catch regressions. Design Patterns: Design patterns are reusable solutions to common software design problems. Design PatternThey provide a template to help structure our code around.One of the most well-known books on design patterns is “Design Patterns: Elements of Reusable Object-Oriented Software”by the “Gang of Four”, which describes 23 patterns. Creational Patterns:These patterns deal with the instantiation of objects. Examples include Abstract Factory, Builder, Factory Method, Prototype, and Singleton. Structural Patterns:These patterns deal with how classes are designed and composed. Examples include Adapter, Bridge, Composite, Decorator, Facade, Flyweight, and Proxy. Behavioral Patterns:These patterns deal with communication between objects. Examples include Chain of Responsibility, Command, Interpreter, Iterator, Mediator, Memento, Observer, State, Strategy, Template Method, and Visitor. By following these principles and patterns, we can create software that is more modular, maintainable, and scalable.","categories":[{"name":"learning log","slug":"learning-log","permalink":"https://www.totrav.com/categories/learning-log/"}],"tags":[{"name":"pipeline","slug":"pipeline","permalink":"https://www.totrav.com/tags/pipeline/"}]},{"title":"Transform Your Workflow: Learn How to Convert Matrices between DCCs","slug":"math-xform-conversion","date":"2022-10-22T07:00:00.000Z","updated":"2023-03-29T21:09:24.000Z","comments":true,"path":"post/math-xform-conversion/","link":"","permalink":"https://www.totrav.com/post/math-xform-conversion/","excerpt":"","text":"IntroductionHave you noticed the different transform values when one asset is importedto a different package? When we do .fbx importing and exporting, the plugin does this conversion forus. FBX is very reliable and hassle-free, but how does the math works? Important: Before continuing, I highly recommend reading these previous posts Euler Angles Change of Basis Transformation ValueTo demonstrate the different transform between DCCs,here I have some ‘axis’ object placed in Maya, Unity and Unreal. When inspecting the ‘axis’ located on the top-right, the transformationvalues are seen as follow: translation rotation scale Maya x: -1.31, y: 0.33, z: 0.19 x: -335, y: -12, z: 98 x: 1, y: 1, z: 1 Unity x: 1.31, y: 0.33, z: 0.19 x: 7, y: -27, z: -102 x: 1, y: 1, z: 1 Unreal x: -1.31, y: 0.19, z: 0.33 x: 149, y: 75, z: 123 x: 1, y: 1, z: 1 Usually, for translation and scale there is a pattern to be found, usuallythe operation involves swapping values between axes, and flipping them. Forrotation, however, the values don’t seem to have connections between oneanother, so how can we compute them? The fundamental reason for all of this is that even though all DCCs use aCartesian coordinate system, they have different axis direction and rotation order. Methods OverviewThe method I use are all fundamental matrix calculation. From the source package, retrieve translation, rotation and scale ($t{source}, r{source}, s{source}$)and compose a transformation matrix: $M{source}$ Convert the transformation matrix to the target software coordinate systemusing change of basis operation: $M{target} = M{cob} M_{source} {M_{cob}}^{-1}$ Decompose the transformation matrix: $M{target}$ and re-order thetarget translation, rotation and scale value such ($t{target}, r{target}, s{target}$) Composition and De-compositionIt is helpful to re-visit the transform matrix calculation, but we will lateruse a math library to handle them. Translation: a translating along $t = $ can be thought as multiplying bythe translation matrix:$M_{translation} =\\begin{bmatrix}1 &amp; 0 &amp; 0 &amp; d_x\\0 &amp; 1 &amp; 0 &amp; d_y\\0 &amp; 0 &amp; 1 &amp; d_z\\0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}$ Scale: a scaling upon $s = &lt;\\betax, \\beta_y, \\beta_z&gt;$ can be thought as multiplyingby the scale matrix:$M{scale} =\\begin{bmatrix}\\beta_x &amp; 0 &amp; 0 &amp; 0\\0 &amp; \\beta_y &amp; 0 &amp; 0\\0 &amp; 0 &amp; \\beta_z &amp; 0\\0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}$ Shear: good to know, but not very commonly use;$sh = $ represents shear along x, y and z axis; $M{sh_x} =\\begin{bmatrix}1 &amp; 0 &amp; 0 &amp; 0\\h{yx} &amp; 1 &amp; 0 &amp; 0\\h{zx} &amp; 0 &amp; 1 &amp; 0\\0 &amp; 0 &amp; 0 &amp; 1 \\\\end{bmatrix}$$M{shy} =\\begin{bmatrix}1 &amp; h{xy} &amp; 0 &amp; 0\\0 &amp; 1 &amp; 0 &amp; 0\\0 &amp; h{zy} &amp; 1 &amp; 0\\0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}$$M{shz} =\\begin{bmatrix}1 &amp; 0 &amp; h{xz} &amp; 0\\0 &amp; 1 &amp; h_{yz} &amp; 0\\0 &amp; 0 &amp; 1 &amp; 0\\0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}$ A 2D shearing operation Rotation: a rotation can be thought as a combination of shearing and scaling,a visual demonstration can be found here. A rotation along x, y and z axis can then be represented as such: $M{r_x} =\\begin{bmatrix}1 &amp; 0 &amp; 0 &amp; 0\\0 &amp; cos\\theta &amp; -sin\\theta &amp; 0\\0 &amp; sin\\theta &amp; cos\\theta &amp; 0\\0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}$$M{ry} =\\begin{bmatrix}cos\\theta &amp; 0 &amp; sin\\theta &amp; 0\\0 &amp; 1 &amp; 0 &amp; 0\\-sin\\theta &amp; 0 &amp; cos\\theta &amp; 0\\0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}$$M{r_z} =\\begin{bmatrix}cos\\theta &amp; -sin\\theta &amp; 0 &amp; 0\\sin\\theta &amp; cos\\theta &amp; 0 &amp; 0\\0 &amp; 0 &amp; 1 &amp; 0\\0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}$ Real ExamplesI used numpy.ndarray to store matrix, and used a third-party libraryfor computing the composition and de-composition of transformation matrix. ComputationNow let’s put our code to the test: Here are the transformation values I have in maya: 123maya_t = [-1.307, 0.331, 0.188]maya_r = [-335, -12, 98]maya_s = [1, 1, 1] Maya to UnityFrom the previous post, I’ve computed the change of basis matrix for Unreal 123456MAYA_TO_UNITY = np.array([ [-1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], dtype=int) Now followed by our methods: 123maya_matrix = compose_matrix(maya_t, maya_r, maya_s, order=&#x27;sxyz&#x27;)unity_matrix = change_xform(maya_matrix, MAYA_TO_UNITY)unity_t, unity_r, unity_s = decompose_matrix(unity_matrix, order=&#x27;szxy&#x27;) Result:1234# transform in Unitytranslation = [1.307, 0.331, 0.188] rotation = [7.3413883536944935, -26.641453221201548, -102.41010358310075] scale = [1.0, 1.0, 1.0] Important: for rotation since the returned values corresponds to the first, secondand third rotation angle specified in the rotation order:which is in ‘zxy’, we need to swap values to re-order it as ‘xyz’. Maya to UnrealSame goes for Unreal, the change of basis matrix is: 123456MAYA_TO_UNREAL = np.array([ [1, 0, 0, 0], [0, 0, -1, 0], [0, 1, 0, 0], [0, 0, 0, 1]], dtype=int) Then comes our conversion method: 123maya_matrix = compose_matrix(maya_t, maya_r, maya_s, order=&#x27;sxyz&#x27;)unreal_matrix = change_xform(maya_matrix, MAYA_TO_UNREAL)unreal_t, unreal_r, unreal_s = decompose_matrix(unreal_matrix, order=&#x27;sxyz&#x27;) Result:1234# transform in Unrealtranslation = [-1.307, 0.188, 0.331] rotation = [149.05728077227823, 75.61041143412538, 123.21509334477231] scale = [1.0, 1.0, 1.0] Caveat: I need to inverse the value of translation z, the reason I haven’t figured out yet,but translation is hardly our concern since we just need to flip axes between Maya values;The rotation value is the important one. ReferenceTransform3d API ThreeJS -Convert from one coordinate system to another? Tech Art Hub - A Practical Guide to Unreal Engine 4’s Coordinate System","categories":[{"name":"learning log","slug":"learning-log","permalink":"https://www.totrav.com/categories/learning-log/"}],"tags":[{"name":"math","slug":"math","permalink":"https://www.totrav.com/tags/math/"},{"name":"maya","slug":"maya","permalink":"https://www.totrav.com/tags/maya/"},{"name":"unreal","slug":"unreal","permalink":"https://www.totrav.com/tags/unreal/"},{"name":"unity","slug":"unity","permalink":"https://www.totrav.com/tags/unity/"}]},{"title":"A Key to Unlocking 3D Software: Understanding Change of Basis Matrix","slug":"math-change-of-basis","date":"2022-09-25T07:00:00.000Z","updated":"2023-09-02T17:48:46.239Z","comments":true,"path":"post/math-change-of-basis/","link":"","permalink":"https://www.totrav.com/post/math-change-of-basis/","excerpt":"","text":"IntroductionDifferent DCCs uses coordinate systems with different axis directions. For example,Maya by default uses a Y-up right-handed system; Unity uses a Y-up left-handed system;and Unreal uses a Z-up left-handed system. (Image from: Techart Hub)&lt;/figure&gt; Up Direction: is what consider to be the up direction of the world. Movingan object up translating in direction of positive Y in Maya and Unity, but forUnreal, it’s translating in the direction of positive Z. Handed System: not only affects the forward/front direction of the world,it also dictates the direction of rotation; for left-handed system,positive rotation about the axis is clockwise, and for right-handed system, it’scounter-clockwise (same way as how our hand would curl, hence the name). The nature of the coordinate system affects how an object’s transformation is calculated. The Change of Basis matrix transforms a vector lies in one coordinate system toanother. Basis VectorsIn the world of 2D, the basis vectors $x$ and $y$ of one coordinate system A,corresponds to$v_x =\\begin{bmatrix}1 \\0 \\\\end{bmatrix}$and$v_y =\\begin{bmatrix}0 \\1 \\\\end{bmatrix}$ Now, if these two basis vectors were to transfer to a different coordinate system B,this exact set of basis vectors is written differently in that system.This represents A’s basis vectors in B’s system.$v_x =\\begin{bmatrix}2 \\1 \\\\end{bmatrix}$and$v_y =\\begin{bmatrix}-1 \\1 \\\\end{bmatrix}$ Correspondingly, any vector in system B could translate to system A, pre-multiply using thischange of basis matrix:$M_{cob} =\\begin{bmatrix}2 &amp; -1\\1 &amp; 1\\\\end{bmatrix}$where the first column is the basis vector $x$ and second column is thebasis vector $y$. And alternatively, to translate any vector in system A to system B, we pre-multiplyby the inverse of this change of basis matrix: ${M_{cob}}^{-1}$. TransformationNow we know how to convert vectors between coordinate systems, how do we do it for transformation?Here are some simple step to understand: Given any vector in system B, apply a change of basis operation, so it’s in system A: $M_{cob} * v_B$. Now we can apply a transformation represented in the same system A: $M{transformA} * M{cob} * v_B$. Finally, we can transfer the end result back to system B by pre-multiplying the inverseof the change of basis matrix: ${M{cob}}^{-1} * M{transformA} M_{cob} v_B$. ConclusionThe frontal part ${M{cob}}^{-1} * M{transformA} * M{cob}$ represents thesame transformation but in system B: $M{transformB}$. Alternatively, any transformation in system B: $M{transformB}$ can be representedas $M{cob} M_{transformB} {M_{cob}}^{-1}$ in system A. Here’s the function I’ve written Python: ExampleMaya to UnrealThe first thing to identify is the change of basis from Maya to Unreal,as illustrated before, Maya is a Y-up left-hand system and Unreal is a Z-upright-hand system. Maya Axis Direction Forward Z Up Y Right -X Unreal Axis Direction Forward -Y Up Z Right -X The change of basis can be represented as such $ M_{cob} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; -1 &amp; 0\\ 0 &amp; 1 &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} $ 123456MAYA_TO_UNREAL = np.array([ [1, 0, 0, 0], [0, 0, -1, 0], [0, 1, 0, 0], [0, 0, 0, 1]], dtype=int) Maya to UnitySame thing for Maya to Unity conversion, a Y-up left-hand system to a Y-up right-handsystem; the $y$ and $z$ are respectively inverted between the two systems, therefore: Maya Axis Direction Forward Z Up Y Right -X Unity Axis Direction Forward Z Up Y Right X The change of basis can be represented as such $ M_{cob} = \\begin{bmatrix} -1 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; 1 &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; 1 &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} $ 123456MAYA_TO_UNITY = np.array([ [-1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], dtype=int) ReferenceYouTube - Change of basis | Chapter 13, Essence of linear algebra Unreal Engine Forum - “Forward” in unreal engine, Which is it? Dario Mazzanti - Change of Basis","categories":[{"name":"3d math","slug":"3d-math","permalink":"https://www.totrav.com/categories/3d-math/"}],"tags":[{"name":"math","slug":"math","permalink":"https://www.totrav.com/tags/math/"},{"name":"maya","slug":"maya","permalink":"https://www.totrav.com/tags/maya/"},{"name":"unreal","slug":"unreal","permalink":"https://www.totrav.com/tags/unreal/"},{"name":"unity","slug":"unity","permalink":"https://www.totrav.com/tags/unity/"}]},{"title":"Euler Angles and Gimbal Lock: Things You Need to Know","slug":"math-euler-gimbal","date":"2022-09-17T07:00:00.000Z","updated":"2023-09-02T17:49:48.029Z","comments":true,"path":"post/math-euler-gimbal/","link":"","permalink":"https://www.totrav.com/post/math-euler-gimbal/","excerpt":"","text":"IntroductionWhen talking about rotation, most of us would picture gimbal movement: an objectrotate about a set of three axes. This is the same principle of the Euler anglespresentation of rotation. It being the most popular representation for rotation,is used across many DCCs, it is intuitive and easy for us to understand. While an Euler angles are usually written as a list of three values representingrotation degrees in x, y, z axis. Scientifically it is actually denoted as$\\alpha$, $\\beta$, $\\gamma$ with radian as rotation unit where $\\alpha$ is rotation about the first axis $\\beta$ is rotation about the second axis $\\gamma$ is rotation about the third axis Rotation OrderThere are two major issue with Euler angles. AmbiguityThe target orientation is rotation order dependent, meaning even with thesame rotation $\\alpha$, $\\beta$, $\\gamma$ values,the results differs using different order of rotation. A zyx order refers to rotation about axis z, y, x in that order (thinkof it as x axis being a child of y axis being a child of z axis).Therefore, to represent a target rotation, aside from providing rotation values$\\alpha$, $\\beta$, $\\gamma$, we also need to providethe rotation order and Rotation Type. There are a total of 12 possible rotation orders per rotation type/group. Gimbal ProblemIn short, the Gimbal problem is due to euler angle decomposing a (linear) rotational movementas a product of more than one axis rotations. Although any target orientation can be achieved using Euler rotation, the rotationalmovements are sometimes undesired. This is due to a problem in Animation field known asGimbal Lock. Gimbal lock happens when two of the three axes are rotated to a parallel configuration, 'locking' the system into a two-dimensional space. In order to “break free” of this configuration,the system needs to input rotation along two or more axes simultaneously. In the context of keyframe Animation, interpolation along more than one axis means therotational movement will not appear linear, but in an unpredictable trajectory,which is bad. (See video illustration here) Test in MayaWe can test out the gimbal problem in Maya ourselves. Going into rotation tools and select “Axis Orientation” to “Gimbal”, we cannow interact with the object using gimbal rotation. This rotation is whatactually get recorded by Maya and presented in the channel box. If we go back to the “Object” mode rotation, even though our rotation gizmo isnow unlocked, the gimbal problem don’t just go away.Maya is still recording the gimbal rotation in the background.The “Object” mode rotation is just an interaction tool. Gimbal Mode Object Mode Quaternion Rotation lies in non-Euclidean space. Luckily there is a more advanced representation for rotation: Quaternion, whichgame engines uses internally. This is due to it being data compact (only stores four numbers) andcomputational efficient (rotational movement using Euler angles usually need to be converted to rotationmatrix, which involves a lot of sin and cos calculation). The bigger advantage comes from itproducing linear and predictable results (the shortest path along source andtarget rotation). It is, however, very hard for users to comprehend. A quaternion consists of a scaler part and a vector part: $q = [s, (x, y, z)]$ where $s, x, y, z \\in R$ or. $q = s + ix + ij + kz$ where $i^2 = j^2 = k^2 = ijk = -1$ Rotation TypeIntrinsic and Extrinsic RotationsIntrinsic rotations are elemental rotations that occur about the axes ofa coordinate system XYZ attached to a moving body. (i.e. rotation about axisin the current coordinate, like object space) Extrinsic rotations are elemental rotations that occurabout the axes of the fixed coordinate system xyz. (i.e. rotation about axisin the original coordinate, like world space) (Fig.1: Intrinsic rotations; Fig.2: Extrinsic rotations) ExampleRotation calculation usually happens along with other transform type using matrix.Here I made a matrix composition and decomposition function in Python, utilizinga third party math library transforms3d. As we can see, since the rotation matrix varies depending on rotation order and type,this is reflected as one of the argument. The first character is ‘r’ (rotating == intrinsic),or ‘s’ (static == extrinsic). The next three characters give the axis (‘x’, ‘y’ or ‘z’)about which to perform the rotation,in the order in which the rotations will be performed. For example the string ‘szyx’ specifies that the angles should be interpretedrelative to extrinsic (static) coordinate axes, and be performed in the order:rotation about z axis; rotation about y axis; rotation about x axis. ConversionAny extrinsic rotation can be represented in intrinsic rotation with the sameangle values but inverted order or elemental rotation. So a $\\alpha$, $\\beta$, $\\gamma$ with extrinsic zyx order is equivalent tothe same angle with intrinsic xyz order. ReferenceStack Exchange - Confusion about order of rotations for Euler Angles Unreal Engine Forum - What is the rotation order for Components or Bones? Stack Exchange - Proof of the extrinsic to intrinsic rotation transform YouTube - Euler (Gimbal Lock) Explained TD Matt - Rotation Orders CSDN - Understanding Euler Angles","categories":[{"name":"3d math","slug":"3d-math","permalink":"https://www.totrav.com/categories/3d-math/"}],"tags":[{"name":"math","slug":"math","permalink":"https://www.totrav.com/tags/math/"},{"name":"maya","slug":"maya","permalink":"https://www.totrav.com/tags/maya/"}]},{"title":"Beginner's Guide to Graphics Lighting and Shading","slug":"graphics-shading-basics","date":"2020-09-16T07:00:00.000Z","updated":"2023-09-02T17:48:27.551Z","comments":true,"path":"post/graphics-shading-basics/","link":"","permalink":"https://www.totrav.com/post/graphics-shading-basics/","excerpt":"","text":"GlossaryWikipedia - Computer Graphics Glossary Shader: programs running on gpu that describes general computation (vertex transformation: vertex shader;shading calculation: fragment shader) G-buffer: a screen space representation of geometry and material information (e.g. color, normal, position/depth) Fragment: is the corresponding pixel generated by geometric primitives,but a pixel on screen can be a product of more than one fragment due to Z-buffering, blending etc. Vertex lighting vs. Per-pixel lighting Vertex Lighting Lighting is computed per-vertex calculation happens in the vertex shader lighting/color information isthen linearly interpolated across faces and rasterized it is cheaper, faster (since there are fewer vertices compared to pixels) but noticeable artifact with low-poly objects Per-Pixel Lighting Lighting is computed per-pixel/fragment (but what is this exactly? see the example below) Calculation happens in the fragment shader normal information (passed from vertex shader) is interpolated on the faces, lighting/color is calculated and rasterized. it is more expensive but less artifact Example of a per-pixel lighting shaderVertex Shader123456789101112131415161718#version 330 corelayout (location = 0) in vec3 aPos;layout (location = 1) in vec3 aNormal;out vec3 FragPos;out vec3 Normal;uniform mat4 model;uniform mat4 view;uniform mat4 projection;void main()&#123; FragPos = vec3(model * vec4(aPos, 1.0)); Normal = mat3(transpose(inverse(model))) * aNormal; gl_Position = projection * view * vec4(FragPos, 1.0);&#125; Fragment Shader123456789101112131415161718192021222324252627282930313233#version 330 coreout vec4 FragColor;in vec3 Normal; in vec3 FragPos; uniform vec3 lightPos; uniform vec3 viewPos; uniform vec3 lightColor;uniform vec3 objectColor;void main()&#123; // ambient float ambientStrength = 0.1; vec3 ambient = ambientStrength * lightColor; // diffuse vec3 norm = normalize(Normal); vec3 lightDir = normalize(lightPos - FragPos); float diff = max(dot(norm, lightDir), 0.0); vec3 diffuse = diff * lightColor; // specular float specularStrength = 0.5; vec3 viewDir = normalize(viewPos - FragPos); vec3 reflectDir = reflect(-lightDir, norm); float spec = pow(max(dot(viewDir, reflectDir), 0.0), 32); vec3 specular = specularStrength * spec * lightColor; vec3 result = (ambient + diffuse + specular) * objectColor; FragColor = vec4(result, 1.0);&#125; As we can see, fragment position and normal information are passed into the fragment shaderfrom vertex shader (where the pre-compute happens), the lighting calculation (Phong lighting)is calculated per-fragment. On a related note: gpu cost are related to how many vertices are passed in to the gpu frombuffer and how complex the lighting calculation is in the fragment shader (this could bethe algorithm/model complexity, and the number of passes); Forward vs. Deferred RenderingForward RenderingThe standard, out-of-the-box rendering technique Geometries are passed to gpu, going through vertex shader and fragment shader,with each geometry and each light computed separately one at a time to form the final render. Render complexity: O(num of geometry fragments * num of lights) Deferred RenderingRender is deferred until all geometry has been processed Geometries are passed to gpu, going through vertex shader and fragment shader (without lighting pass),final rendering is computed/combined with multiple render passes(one pass for getting all geometry information to G-buffer,second pass for compute lighting based on the G-buffer). Render complexity: O(screen resolution * num of lights) DiscussionEverything all comes down to lighting, as gpu can easily handle vertex information,but the most expensive are lighting calculation which can easily slow down the rendering.Forward rendering iterates and compute each fragments of each geometry, no matter if it overlaps or is hiddenby other fragments. So for each pixel, we could have already run multiple fragment shaders. This is where deferred rendering come in handy, the G-buffer stores information such as color, normal and depth.The lighting later on can know how to produce the final render by combining all the information (For example: depth test canalso cull out all the fragments that are being obscured). So essentially, each pixel only runs a single fragment shader. Rasterization vs. Ray tracingThe forward, deferred rendering techniques are all in the realm of rasterization, which is themost popular and traditional real-time rendering technique. With the advance of hardware, ray tracing,which is computationally demanding (usually used in films/animation) can now be used inreal-time video games. RasterizationWe gather objects information and projects each one by one on screen (per fragment), fragment shadercomputes the final color of every fragment to form pixels on screen. The fundamental of rasterizing is that for each object/geometry, we look at (rasterize it) it’s verts/triangles to cover pixels. So, as discussed in deferred rendering, every object is drawn but not all of them are displayed on screen.This overdraw can be accelerated by using deferred shading’s depth test. Ray tracingWe cast rays from our eyes (camera) for each pixel and gather information of those rays as they travelthrough/intersects with objects and interacts with lightsto form the final render on screen. The fundamental of ray tracing is that for each pixel, we look at (shoot a ray) each object/geometry to seehow they contribute to the color of that pixel. As for ray tracing, we need to shoot many rays for each pixel, and more when there are reflection and refraction.One way to accelerate this is to use bounding volume. DiscussionThe most significant difference in visual is that ray tracing is physically more accuratethan rasterization, thus more realistic. Which is more apparent in dynamic environment withobjects that reflects and refract. Rasterization needs many estimation techniques to handle lighting and shadowingsuch as more render passes, baked light map, cubemap reflection, but ray tracing gets all the results out of the box. ReferenceEnvato tuts+ - Forward Rendering vs. Deferred Rendering Learn OpenGL - Deferred Shading Wikipedia - Deferred Lighting Learn OpenGL - Basic Lighting Knowww - Per-vertex vs. per-fragment lighting Unity Forum - What’s the difference between per-pixel and per-vertex lit in Forward Rendering? Youtube - OpenGL Fragment Shaders | How Do Fragment Shaders Work? Nvidia - Ray Tracing Essentials Stack Exchange - Mirror Reflections: Ray Tracing or Rasterization? Quora - What is the difference between ray tracing and very high shader details?","categories":[{"name":"graphics programming","slug":"graphics-programming","permalink":"https://www.totrav.com/categories/graphics-programming/"}],"tags":[{"name":"rendering","slug":"rendering","permalink":"https://www.totrav.com/tags/rendering/"}]},{"title":"Comprehensive Guide to C++ Reference and Pointer","slug":"cpp-reference-pointer","date":"2020-08-13T07:00:00.000Z","updated":"2023-03-29T21:04:08.000Z","comments":true,"path":"post/cpp-reference-pointer/","link":"","permalink":"https://www.totrav.com/post/cpp-reference-pointer/","excerpt":"","text":"BasicsDe-referencing add * before a pointer to expose the object’s value it’s pointing varN, varN’s value ptrN, varN’s address *ptrN, de-reference ptrN, varN’s value (&amp;ptrN, ptrN’s address, which has little meaning) Symbol to access a member of a class or class object (instance) a-&gt;b: b is the member of the object that pointer a refers to a.b: b is the member of the object, or the reference of an object a a::b: b is the member of the class, or namespace a DeclarationPointer DeclarationSyntax: varType* varName Declaration12//declare a c++ pointer to an integerint* ptrx; Initialization1234// a pointer pointing to address of varN, varN type should be intint varN = 9;int* ptrN;ptrN = &amp;varN; short-hand:1int* ptrN = &amp;varN; Reference DeclarationSyntax: varType&amp; varName 123456789int main()&#123; int&amp; invalidRef; // error: references must be initialized int x = 5; int&amp; ref = x; // okay: reference to int is bound to int variable return 0;&#125; When a reference is initialized with an object (or function), we say it is bound to that object (or function). The process by which such a reference is bound is called reference binding references must be bound to a modifiable variable Function Pass Argument Both of these methods are prevented copying the variable, and capable of modifying the variable value that is passed in; if a variable is expensive to copy, e.g. struct, class By Reference Modify the variable, can’t pass in an un-modifiable variable like const Syntax varType&amp; varName 1234void printValue(int&amp; y)&#123; std::cout &lt;&lt; y &lt;&lt; &#x27;\\n&#x27;;&#125; Prevent modifying the variable, while having the benefit of not making a copy Syntax const varType&amp; varName 1234void printValue(const int&amp; y)&#123; std::cout &lt;&lt; y &lt;&lt; &#x27;\\n&#x27;;&#125; By Address (via pointer)Syntax varType* varName, to access the variable, de-reference using *varName 1234void printByAddress(const std::string* ptr) // The function parameter is a pointer that holds the address of str&#123; std::cout &lt;&lt; *ptr &lt;&lt; &#x27;\\n&#x27;; // print the value via the dereferenced pointer&#125; Function Return ArgumentVariable Pointerworks almost identically to return by reference, except a pointer to an object is returned instead of a reference to an object The major advantage of return by address over return by reference is that we can have the function return nullptr if there is no valid object to return Variable Reference Never return a reference to a local variable or some such, because it won’t be there to be referenced. Syntax varType&amp; funName(args) ReferencesStack Overflow - When do I use a dot, arrow, or double colon to refer to members of a class in C++? Runestone Academy - Pointers Learn C++ - Lvalue reference Learn C++ - Return by reference and return by address Learn C++ - Pass by lvalue reference Learn C++ - Pass by address","categories":[{"name":"learning log","slug":"learning-log","permalink":"https://www.totrav.com/categories/learning-log/"}],"tags":[{"name":"c++","slug":"c","permalink":"https://www.totrav.com/tags/c/"}]},{"title":"Maya Python API Tutorial Series (3. Custom Deformer)","slug":"maya-api-deformer","date":"2019-11-11T08:00:00.000Z","updated":"2023-03-29T21:10:12.000Z","comments":true,"path":"post/maya-api-deformer/","link":"","permalink":"https://www.totrav.com/post/maya-api-deformer/","excerpt":"","text":"API 1.0 custom deformer Example Note: MPxDeformerNode is only available in API 2.0 Custom Attribute vs. Built-in Attribute In the last chapter, we know how to create custom numeric type attribute using MFnNumericAttribute.Sometimes in our node, we want to access existing built-in attribute.We do so by using OpenMayaMPx.cvar.MPxDeformerNode_(attributeName) before Maya 2016,we use OpenMayaMPx.cvar.MPxGeometryFilter_(attributeName) after 2016. Obtain Input Geometry In the sample code, we define our custom function getDeformerInputGeom(self, dataBlock, geomIndex)to obtain the input mesh to the deformer node. We will discuss this later. Accessory Node Accessory node acts like a secondary driver node connected to our deformer so they can influence the deformation. In the sample code, our accessory node is a locator which when we connects its world matrix, it will change our mesh’s deformation when translating. Custom Dependency Node vs. Custom Deformer Node Registration:In our previous chapter, we register our node using registerNode() withnode type: omMPx.MPxNode.kDependNode,in deformer node, we use omMPx.MPxNode.kDeformerNode as our node type. Inheritance:We now inherit our class from omMPx.MPxDeformerNode instead of omMPxNodethere’s still compute() in MPxDeformerNode class,but we want to write our deformation algorithm in deform(). Accessory Node:accessoryNodeSetup(self, dagModifier) and accessoryAttribute(self) is override to allow us to control accessory node along with our deformer. ProcedureStep 1: Declare attributes (Same as last chapter)Step 2: Initialize NodeNode Creator12def nodeCreator(): return mpx.asMPxPtr(MyDeformer()) Only API 1.0 is available. Node Initializer 12345678910111213141516171819202122232425262728def nodeInitializer(): # 1: create reference to numericAttribute and matrixAttribute function sets numericAttrFn = om.MFnNumericAttribute() matrixAttrFn = om.MFnMatrixAttribute() # 2: create attribute using the function set MyDeformer.inNumAttr = numericAttrFn.create(&#x27;num&#x27;, &#x27;n&#x27;, om.MFnNumericData.kFloat, 0.0) numericAttrFn.setMin(-1.0) numericAttrFn.setMax(1.0) numericAttrFn.setReadable(False) MyDeformer.inMatAttr = numericAttrFn.create(&#x27;matrix&#x27;, &#x27;m&#x27;) matrixAttrFn.setStorable(False) matrixAttrFn.setConnectable(True) # 2.5: access built-in attribute using OpenMayaMpx.cvar.MPxGeometryFilter_outputGeom outputGeom = mpx.cvar.MPxGeometryFilter_outputGeom # 3: attach attribute MyDeformer.addAttribute(MyDeformer.inNumAttr) MyDeformer.addAttribute(MyDeformer.inMatAttr) # 4: add circuit (relationship in-&gt;out) MyDeformer.attributeAffects(MyDeformer.inNumAttr, ouputGeom) MyDeformer.attributeAffects(MyDeformer.inMatAttr, ouputGeom) # 5: make attribute paintable cmds.makePaintable(nodeName, &#x27;weights&#x27;, attrType=&#x27;multiFloat&#x27;, shapeMode=&#x27;deformer&#x27;) we access the output Geometry attribute so we can later add relationship to it. RegisterNode 1mplugin.registerNode(nodeName, nodeID, nodeCreator, nodeInitializer, om.MPxNode.kDeformNode) De-registerNode 1mplugin.deregisterNode(nodeID) Step 3: Initialize Node （Deform Algorithm）1234567891011121314151617181920212223242526272829303132333435363738394041424344class MyNode(om.MPxDeformNode): inNumAttr = om.MObject() inMatAttr = om.MObject() def __init__(self): om.MPxDeformNode.__init__(self) def deform(self, dataBlock, geomIterator, localToWorldMatrix, geomIndex): # step 1: access built-in attribute value using attribute name and attribute handle envelopeAttr = mpx.cvar.MPxGeometryFilter_envelope envelopeHandle = dataBlock.inputValue(envelopeAttr) envelopeValue = envelopeHandle.asFloat() # step 1.5: access custom attribute value inNumHandle = dataBlock.inputValue(MyDeformer.inNumAttr) inNumValue = inNumHandle.asFloat() # step 1.55: access custom translate value connected to an accessory node inMatHandle = dataBlock.inputValue(MyDeformer.inMatAttr) inMatValue = inNumHandle.asMatrix() transMatrix = om.MTransformationMatrix(inMatValue) # matrix type translateValue = transMatrix.getTranslation(om.MSpace.kObject) # vector type # step 2: access input mesh inputMesh = self.getDeformerInputGeom(dataBlock, geomIndex) # step 2.5: access mesh normals meshFn = om.MFnMesh(inputMesh) normalVectorArray = om.MFloatVectorArray() # create float vector array to store normal vector meshFn.getVertexNormals(False, normalVectorArray, om.MSpace.kObject) # (average normal or not?, the array to store, normal space) # step 3: iterate the mesh vertices and deform it newVertexPosArray = om.MPointArray() # to store new vertices position while not geomIterator.isDone(): vertexPos = geomIterator.position() vertexIndex = geomIterator.index() normalVector = om.MVector(normalVectorArray[vertexIndex]) # built-in function weightValue(dataBlock, geomIndex, vertexIndex) weight = self.weightValue(dataBlock, geomIndex, vertexIndex) # vertexPos.x = vertexPos.x + [calculation of normalVector.x and translateValue[0]] * envelopeValue * weight newVertexPosArray.append(vertexPos) geomIterator.next() geomIterator.setAllPositions(newVertexPosArray) To access a value from an attribute, we use handle = dataBlock.input/outputValue(MyNode.attr) if we have a custom attribute inNumAttr: inNumHandle = dataBlock.inputValue(MyDeformer.inNumAttr) inNumValue = inNumHandle.asFloat() if we have a built-in attribte envelope: we first get our attribute name envelope envelopeAttr = mpx.cvar.MPxGeometryFilter_envelope envelopeHandle = dataBlock.inputValue(envelopeAttr) envelopeValue = envelopeHandle.asFloat() To get normal for individual vertices on our input mesh,we first need to obtain our input mesh using our own function:getDeformerInputGeom(self, dataBlock, geomIndex).And using mesh function set MeshFn’s getVertexNormals() we store thenormal vector in om.MFloatVectorArray() type array. To deform our mesh: we use the geometry iterator to perform iteration oneach mesh vertex and re-calculate its position.We combine the use of geoIterator.position() andgeomIterator.setPosition(point) or geomIterator.setAllPositions(pointArray). To access weight value on each vertex, we use built-infunction weightValue(dataBlock, geomIndex, vertexIndex).In which, geomIndex is provided in deform() and vertexIndex is from geomIterator. Step 3.1: Get in-Mesh1234567891011def getDeformerInputGeom(self, dataBlock, geomIndex): inputAttr = mpx.cvar.MPxGeometryFilter_input inputHandle = dataBlock.outputArrayValue(inputAttr) # use outputArray instead of inputArray to avoid re-computation inputHandle.jumpToElement(geomIndex) inputElementHandle = inputHandle.outputValue() inputGeomAttr = mpx.cvar.MPxGeometryFilter_inputGeom inputGeomHandle = inputElementHandle.child(inputGeomAttr) # this is different from how we usually get handler inputGeomMesh = inputGeomHandle.asMesh() return inputGeomMesh At this point, I can’t fully interpret the meaning of this segment. Step 4: Accessory Node1234567891011121314151617181920def accessoryNodeSetup(self, dagModifier): # step1: create the accessory node using the supplied dagModifier locator = dagModifier.createNode(&#x27;locator&#x27;) # step2: access accessory node&#x27;s attribute(can&#x27;t use mplug type, has to be mobject type) # access dependency node function set dependNodeFn = om.MFnDependencyNode(locator) matrixPlug = dependNodeFn.findPlug(&#x27;worldMatrix&#x27;) # this returns mplug type attribute, we need mobject type attribute matrixAttr = matrixPlug.attribute() # step3: connect mobject type(required) together # param: accessory node(mobject), accessory attr(mobject), deformer node(mobject: using self.thisMObject()), deformer attr(mobject) mConnectStatus = dagModifier.connect(locator, matrixAttr, self.thisMObject(), MyDeformer.inMatAttr) # now the accessory node&#x27;s worldMatrix is driving to the custom in-matrix of the deformer node return mConnectStatusdef accessoryAttribute(self): # returns the deformer node attribute connected return MyDeformer.inMatAttr The dagModifer is supplied in the accessory node. We use dagModifier’s connect function toconnect the accessory node’s attribute to our deformer node’s attribute.In this case, we have accessory’s attribute: worldMatrix(a built-in attribute obtained from MFnDependencyNode.findPlug())and our custom defined MyDeformer.inMatAttr. One thing to note is that, the .connect() only takes MObject which we cannot supply MPlug typeobject matrixPlug = ...findPlug(&#39;attributeName&#39;), we perform an additional stepmatrixAttr = matrixPlug.attribute() to get the MObject type attribute. Now we supply .connect() with parameters: an accessory node (MObject type),accessory node’s attribute (MObject type), deformer node (MObject type)and deformer node’s attribute (MObject type) as follows:mConnectStatus = dagModifier.connect(locator, matrixAttr, self.thisMObject(), MyDeformer.inMatAttr) ReferenceChad Vernon - Maya API Programming","categories":[{"name":"maya python api","slug":"maya-python-api","permalink":"https://www.totrav.com/categories/maya-python-api/"}],"tags":[{"name":"maya","slug":"maya","permalink":"https://www.totrav.com/tags/maya/"},{"name":"python","slug":"python","permalink":"https://www.totrav.com/tags/python/"}]},{"title":"Maya Python API Tutorial Series (1. Command Plugin with Flags)","slug":"maya-api-command","date":"2019-09-29T07:00:00.000Z","updated":"2023-03-29T21:10:12.000Z","comments":true,"path":"post/maya-api-command/","link":"","permalink":"https://www.totrav.com/post/maya-api-command/","excerpt":"","text":"“Flags” vs “Argument”Take this as an example: cmds.group(&#39;circle1&#39;, &#39;sphere1&#39;, name=&#39;group1&#39;) circle1 and sphere1 are arguments name is the flag and group1 is the value Another example: cmds.polyCube(sx=10, axis=[0, 0, 1]) no argument is specified sx is the flag’s short name, subdivisionX is the flag’s long name [0, 0, 1] is axis flag’s value, each individual number is called parameters ProcedureStep 1: Declare flag name outside the class12345firstFlagShortName = &#x27;-f&#x27;firstFlagLongName = &#x27;-first&#x27;secondFlagShortName = &#x27;-s&#x27;secondFlagLongName = &#x27;-second&#x27;# more flags ... Step 2: Add flag and argument in syntax creator outside of class(this syntax creator will be further included in the plugin initialize function) 1234567891011121314151617def syntaxCreator(): &quot;&quot;&quot; create a OpenMaya.MSyntax object to store flags and argument &quot;&quot;&quot; syntax = om.MSyntax() # add flags with short name, long name, and value type syntax.addFlag(firstFlagShortName, firstFlagLongName, om.MSyntax.kDouble) syntax.addFlag(secondFlagShortName, secondFlagLongName, (om.MSyntax.kDouble, om.MSyntax.kDouble, om.MSyntax.kDouble)) # add more flags ... # add argument using MSyntax.addArg() function # add argument is not discussed, refer to document later return syntax Step 3: Parsing flags, called inside the class’s doIt function123456789101112131415def parseArguments(self, args): &quot;&quot;&quot; instantiate MArgParser object, self.syntax() refers to the syntax created in step 2 &quot;&quot;&quot; argData = om.MArgParser(self.syntax(), args) # check if certain flags are set if argData.isFlagSet(firstFlagShortName): firstValue = argData.flagArgumentString(firstFlagShortName, 0) if argData.isFlagSet(secondFlagShortName): secondParam0 = argData.flagArgumentInt(secondFlagShortName, 0) secondParam1 = argData.flagArgumentInt(secondFlagShortName, 1) secondParam2 = argData.flagArgumentInt(secondFlagShortName, 2) # parse more flags ... ReferenceChad Vernon - Maya API Programming","categories":[{"name":"maya python api","slug":"maya-python-api","permalink":"https://www.totrav.com/categories/maya-python-api/"}],"tags":[{"name":"maya","slug":"maya","permalink":"https://www.totrav.com/tags/maya/"},{"name":"python","slug":"python","permalink":"https://www.totrav.com/tags/python/"}]}],"categories":[{"name":"learning log","slug":"learning-log","permalink":"https://www.totrav.com/categories/learning-log/"},{"name":"3d math","slug":"3d-math","permalink":"https://www.totrav.com/categories/3d-math/"},{"name":"graphics programming","slug":"graphics-programming","permalink":"https://www.totrav.com/categories/graphics-programming/"},{"name":"maya python api","slug":"maya-python-api","permalink":"https://www.totrav.com/categories/maya-python-api/"}],"tags":[{"name":"pipeline","slug":"pipeline","permalink":"https://www.totrav.com/tags/pipeline/"},{"name":"math","slug":"math","permalink":"https://www.totrav.com/tags/math/"},{"name":"maya","slug":"maya","permalink":"https://www.totrav.com/tags/maya/"},{"name":"unreal","slug":"unreal","permalink":"https://www.totrav.com/tags/unreal/"},{"name":"unity","slug":"unity","permalink":"https://www.totrav.com/tags/unity/"},{"name":"rendering","slug":"rendering","permalink":"https://www.totrav.com/tags/rendering/"},{"name":"c++","slug":"c","permalink":"https://www.totrav.com/tags/c/"},{"name":"python","slug":"python","permalink":"https://www.totrav.com/tags/python/"}]}